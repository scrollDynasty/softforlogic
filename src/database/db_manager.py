import sqlite3
import asyncio
import os
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import asdict
import aiosqlite

from ..utils.logger import logger

class DatabaseManager:
    def __init__(self, db_path: str = "data/loads.db"):
        self.db_path = db_path
        self._ensure_data_directory()
        
    def _ensure_data_directory(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
    
    async def init_database(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–∞–±–ª–∏—Ü"""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                # –¢–∞–±–ª–∏—Ü–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –≥—Ä—É–∑–æ–≤
                await db.execute('''
                    CREATE TABLE IF NOT EXISTS sent_loads (
                        load_id TEXT PRIMARY KEY,
                        load_hash TEXT UNIQUE,
                        sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        pickup_location TEXT,
                        delivery_location TEXT,
                        rate REAL,
                        miles INTEGER,
                        deadhead INTEGER,
                        profitability_score REAL,
                        equipment_type TEXT,
                        pickup_date TEXT,
                        status TEXT DEFAULT 'sent',
                        priority TEXT DEFAULT 'MEDIUM'
                    )
                ''')
                
                # –¢–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                await db.execute('''
                    CREATE TABLE IF NOT EXISTS monitoring_stats (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        loads_found INTEGER DEFAULT 0,
                        loads_sent INTEGER DEFAULT 0,
                        avg_scan_time_ms INTEGER DEFAULT 0,
                        errors_count INTEGER DEFAULT 0,
                        session_active BOOLEAN DEFAULT 1,
                        memory_usage REAL DEFAULT 0,
                        cpu_usage REAL DEFAULT 0
                    )
                ''')
                
                # –¢–∞–±–ª–∏—Ü–∞ –ª–æ–≥–æ–≤ –æ—à–∏–±–æ–∫
                await db.execute('''
                    CREATE TABLE IF NOT EXISTS error_log (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        error_type TEXT,
                        error_message TEXT,
                        stack_trace TEXT,
                        screenshot_path TEXT,
                        context TEXT
                    )
                ''')
                
                # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                await db.execute('''
                    CREATE TABLE IF NOT EXISTS performance_log (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        operation TEXT,
                        duration_ms REAL,
                        success BOOLEAN,
                        details TEXT
                    )
                ''')
                
                # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
                await db.execute('CREATE INDEX IF NOT EXISTS idx_sent_loads_timestamp ON sent_loads(sent_at)')
                await db.execute('CREATE INDEX IF NOT EXISTS idx_sent_loads_hash ON sent_loads(load_hash)')
                await db.execute('CREATE INDEX IF NOT EXISTS idx_monitoring_stats_timestamp ON monitoring_stats(timestamp)')
                await db.execute('CREATE INDEX IF NOT EXISTS idx_error_log_timestamp ON error_log(timestamp)')
                
                await db.commit()
                logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                return True
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            return False
    
    async def is_load_new(self, load_id: str, load_hash: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≥—Ä—É–∑ –Ω–æ–≤—ã–º"""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute(
                    'SELECT 1 FROM sent_loads WHERE load_id = ? OR load_hash = ?',
                    (load_id, load_hash)
                )
                result = await cursor.fetchone()
                return result is None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ–≥–æ –≥—Ä—É–∑–∞: {e}")
            return True  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å—á–∏—Ç–∞–µ–º –≥—Ä—É–∑ –Ω–æ–≤—ã–º
    
    async def mark_as_sent(self, load_data: dict, analysis: dict) -> bool:
        """–û—Ç–º–µ—Ç–∫–∞ –≥—Ä—É–∑–∞ –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ"""
        try:
            load_hash = self.generate_load_hash(load_data)
            
            async with aiosqlite.connect(self.db_path) as db:
                await db.execute('''
                    INSERT INTO sent_loads (
                        load_id, load_hash, pickup_location, delivery_location,
                        rate, miles, deadhead, profitability_score, equipment_type,
                        pickup_date, priority
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    load_data.get('id'),
                    load_hash,
                    load_data.get('pickup'),
                    load_data.get('delivery'),
                    load_data.get('rate'),
                    load_data.get('miles'),
                    load_data.get('deadhead'),
                    analysis.get('profitability_score', 0),
                    load_data.get('equipment'),
                    load_data.get('pickup_date'),
                    analysis.get('priority', 'MEDIUM')
                ))
                
                await db.commit()
                logger.debug(f"‚úÖ –ì—Ä—É–∑ {load_data.get('id')} –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π")
                return True
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä—É–∑–∞ –≤ –ë–î: {e}")
            return False
    
    def generate_load_hash(self, load_data: dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à–∞ –≥—Ä—É–∑–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π
        key_fields = [
            str(load_data.get('id', '')),
            str(load_data.get('pickup', '')),
            str(load_data.get('delivery', '')),
            str(load_data.get('rate', '')),
            str(load_data.get('miles', '')),
            str(load_data.get('deadhead', ''))
        ]
        
        hash_string = '|'.join(key_fields)
        return hashlib.md5(hash_string.encode()).hexdigest()
    
    async def cleanup_old_records(self, days: int = 7) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            
            async with aiosqlite.connect(self.db_path) as db:
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –≥—Ä—É–∑–æ–≤
                cursor = await db.execute(
                    'DELETE FROM sent_loads WHERE sent_at < ?',
                    (cutoff_date.isoformat(),)
                )
                loads_deleted = cursor.rowcount
                
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ –æ—à–∏–±–æ–∫
                cursor = await db.execute(
                    'DELETE FROM error_log WHERE timestamp < ?',
                    (cutoff_date.isoformat(),)
                )
                errors_deleted = cursor.rowcount
                
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                cursor = await db.execute(
                    'DELETE FROM performance_log WHERE timestamp < ?',
                    (cutoff_date.isoformat(),)
                )
                perf_deleted = cursor.rowcount
                
                await db.commit()
                
                total_deleted = loads_deleted + errors_deleted + perf_deleted
                logger.info(f"üßπ –û—á–∏—â–µ–Ω–æ {total_deleted} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π")
                return total_deleted
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ë–î: {e}")
            return 0
    
    async def get_daily_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –¥–µ–Ω—å"""
        try:
            today = datetime.now().date()
            start_date = datetime.combine(today, datetime.min.time())
            end_date = datetime.combine(today, datetime.max.time())
            
            async with aiosqlite.connect(self.db_path) as db:
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –≥—Ä—É–∑–æ–≤
                cursor = await db.execute('''
                    SELECT COUNT(*) as total_sent,
                           AVG(profitability_score) as avg_profitability,
                           AVG(rate) as avg_rate,
                           SUM(miles) as total_miles
                    FROM sent_loads 
                    WHERE sent_at BETWEEN ? AND ?
                ''', (start_date.isoformat(), end_date.isoformat()))
                
                loads_stats = await cursor.fetchone()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                cursor = await db.execute('''
                    SELECT SUM(loads_found) as total_found,
                           SUM(loads_sent) as total_sent_monitoring,
                           AVG(avg_scan_time_ms) as avg_scan_time,
                           SUM(errors_count) as total_errors
                    FROM monitoring_stats 
                    WHERE timestamp BETWEEN ? AND ?
                ''', (start_date.isoformat(), end_date.isoformat()))
                
                monitoring_stats = await cursor.fetchone()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫
                cursor = await db.execute('''
                    SELECT COUNT(*) as total_errors,
                           COUNT(DISTINCT error_type) as unique_error_types
                    FROM error_log 
                    WHERE timestamp BETWEEN ? AND ?
                ''', (start_date.isoformat(), end_date.isoformat()))
                
                error_stats = await cursor.fetchone()
                
                return {
                    'date': today.isoformat(),
                    'loads_sent': loads_stats[0] if loads_stats else 0,
                    'avg_profitability': loads_stats[1] if loads_stats else 0,
                    'avg_rate': loads_stats[2] if loads_stats else 0,
                    'total_miles': loads_stats[3] if loads_stats else 0,
                    'loads_found': monitoring_stats[0] if monitoring_stats else 0,
                    'avg_scan_time_ms': monitoring_stats[2] if monitoring_stats else 0,
                    'total_errors': error_stats[0] if error_stats else 0,
                    'unique_error_types': error_stats[1] if error_stats else 0
                }
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}
    
    async def log_monitoring_cycle(self, stats: dict) -> bool:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–∏–∫–ª–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                await db.execute('''
                    INSERT INTO monitoring_stats (
                        loads_found, loads_sent, avg_scan_time_ms,
                        errors_count, session_active, memory_usage, cpu_usage
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    stats.get('loads_found', 0),
                    stats.get('loads_sent', 0),
                    stats.get('avg_scan_time_ms', 0),
                    stats.get('errors_count', 0),
                    stats.get('session_active', True),
                    stats.get('memory_usage', 0),
                    stats.get('cpu_usage', 0)
                ))
                
                await db.commit()
                return True
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
            return False
    
    async def log_error(self, error_type: str, error_msg: str, 
                       stack_trace: str = "", screenshot_path: str = "", 
                       context: str = "") -> bool:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏"""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                await db.execute('''
                    INSERT INTO error_log (
                        error_type, error_message, stack_trace, 
                        screenshot_path, context
                    ) VALUES (?, ?, ?, ?, ?)
                ''', (error_type, error_msg, stack_trace, screenshot_path, context))
                
                await db.commit()
                return True
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–∫–∏: {e}")
            return False
    
    async def log_performance(self, operation: str, duration_ms: float, 
                            success: bool = True, details: str = "") -> bool:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            async with aiosqlite.connect(self.db_path) as db:
                await db.execute('''
                    INSERT INTO performance_log (
                        operation, duration_ms, success, details
                    ) VALUES (?, ?, ?, ?)
                ''', (operation, duration_ms, success, details))
                
                await db.commit()
                return True
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return False
    
    async def get_performance_report(self, hours: int = 24) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            
            async with aiosqlite.connect(self.db_path) as db:
                cursor = await db.execute('''
                    SELECT operation,
                           COUNT(*) as count,
                           AVG(duration_ms) as avg_duration,
                           MIN(duration_ms) as min_duration,
                           MAX(duration_ms) as max_duration,
                           SUM(CASE WHEN success THEN 1 ELSE 0 END) as success_count
                    FROM performance_log 
                    WHERE timestamp > ?
                    GROUP BY operation
                    ORDER BY avg_duration DESC
                ''', (cutoff_time.isoformat(),))
                
                results = await cursor.fetchall()
                
                report = {
                    'period_hours': hours,
                    'operations': []
                }
                
                for row in results:
                    operation, count, avg_dur, min_dur, max_dur, success_count = row
                    success_rate = (success_count / count) * 100 if count > 0 else 0
                    
                    report['operations'].append({
                        'operation': operation,
                        'count': count,
                        'avg_duration_ms': avg_dur,
                        'min_duration_ms': min_dur,
                        'max_duration_ms': max_dur,
                        'success_rate_percent': success_rate
                    })
                
                return report
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return {}
    
    async def get_db_size_mb(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ –ú–ë"""
        try:
            if os.path.exists(self.db_path):
                size_bytes = os.path.getsize(self.db_path)
                return size_bytes / (1024 * 1024)
            return 0
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –ë–î: {e}")
            return 0
    
    async def backup_database(self, backup_path: str = None) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if backup_path is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_path = f"data/backup_loads_{timestamp}.db"
            
            os.makedirs(os.path.dirname(backup_path), exist_ok=True)
            
            # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ë–î
            import shutil
            shutil.copy2(self.db_path, backup_path)
            
            logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return False
